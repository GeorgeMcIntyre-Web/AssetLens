services:
  inference:
    build:
      context: .
      dockerfile: services/inference/Dockerfile
    ports:
      - "8000:8000"
    environment:
      - ASSETLENS_DATA_DIR=/app/services/inference/data
    volumes:
      - ./services/inference/data:/app/services/inference/data

  web:
    build:
      context: .
      dockerfile: apps/web/Dockerfile
    ports:
      - "3000:3000"
    environment:
      - NEXT_PUBLIC_API_BASE_URL=http://localhost:8000
      - NEXT_PUBLIC_MOCK_MODE=${NEXT_PUBLIC_MOCK_MODE:-false}
    depends_on:
      - inference
